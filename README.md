This was an analysis of a poker database of 120 million hands. I hope to pick this back up using Hadoop in the future, since most of the analysis requires aggregation.

Walkthrough of beginning part of the analysis is below:
* [Part A](http://nbviewer.ipython.org/github/joshplotkin/Poker-Database-Analysis/blob/master/Stage%20A%20Code/StageA.ipynb)
* [Part B](http://nbviewer.ipython.org/github/joshplotkin/Poker-Database-Analysis/blob/master/Stage%20B%20Code/StageB.ipynb)
* [Part C](http://nbviewer.ipython.org/github/joshplotkin/Poker-Database-Analysis/blob/master/Stage%20C%20Code/StageC.ipynb)
* [Trying D3-based animation library in python](http://nbviewer.ipython.org/github/joshplotkin/Poker-Database-Analysis/blob/master/Stage%20C%20Code/Blog%20Post%203.ipynb)
* [Part D](http://nbviewer.ipython.org/github/joshplotkin/Poker-Database-Analysis/blob/master/Stage%20D%20Code/StageD.ipynb)
* Charts generated by comparing different dimensions are in Stage E

The other parts are mostly just a lot of python scripts to manipulate the csv files (which total roughly 160 GB) chunk by chunk.
